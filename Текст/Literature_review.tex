\section{Обзор литературы}

На данный момент существует одна релевантная моему исследованию статья про работу конкретно в татарском языке, однако она не содержит в себе использование методов современного машинного обучения. Также есть работы на темы других языков с малыми ресурсами и работы о моделях, которые были полезны в моей работе.

\subsection{Named Entity Recognition in Tatar: Corpus-Based Algorithm}

Самая близкая к моей работе это статья <<Named Entity Recognition in Tatar:
Corpus-Based Algorithm>> от О. Невзоровой, Д. Мухамедшина и А. Галиевой, Академия наук Республики Татарстан. В статье они рассказывают, как разметили корпус <<Туган Тел>>[ссылка], использовав следующие категории: книги, рестораны, фильмы, журналы, компании, аэропорты, корпорации, языки, колледжи, университеты, школы, магазины, музеи и больницы. Несмотря на наличие в названии распознавания именованных сущностей, они скорее использовали полуручной метод разметки. 

TODO сделай везде доллары, где есть математика!!!

TODO Тут будет описание их статьи.

TODO Куда вставить описание Туган Тел?

\subsubsection{Использованные данные}

Туган Тел -- это корпус текстов на татарском языке, разработанный Институтом прикладной
семиотики Академии наук Республики Татарстан. Корпус предназначен для широкого круга 
пользователей: лингвистов, специалистов в татарском языке, преподавателей татарского и всем 
тем, кому может понадобиться набор текстов на татарском языке. Основными функциями корпуса 
являются: поиск  по словоформе, лемме (лексеме), набору морфологических параметров. 
Существует система <<корпус-менеджер>>, которая поддерживает данные функции.  На данный 
момент существует проект разработки электронного корпуса, который также включает в себя 
автоматическую разметку корпуса, чем и занималась команда Невзоровой. Корпус включает в 
себя татарские тексты различных жанров, такие как художественная литература, тексты СМИ, 
тексты официальных документов, учебная литература, научные публикации и др. Каждый
документ имеет метаописание, включающее в себя автора и его пол, выходные данные, дату 
создания, жанр, части, главы и др. Тексты, включенные в корпус, снабжены автоматической 
морфологической разметкой, которая включает в себя информацию о части речи и 
грамматической характеристики словоформы. Морфологическая разметка текстов корпуса 
выполняется автоматически с использованием модуля двухуровневого морфологического анализа 
татарского языка, реализованного в программном инструментарии PC-KIMMO, с чем связан ряд 
проблем в использовании данного корпуса, о которых я скажу в основной части работы. На 
декабрь 2019 года в корпусе 194 млн. словоформ. 

TODO Нужен ли этот абзац или нафиг его надо?

В качестве релевантных статей Невзорова at al указывают LingPipe[ссылка], команда которой 
решает похожую задачу в английском языке (TODO проверить, так ли это, и о чём вообще статья), 
Annie[ссылка], Afner[ссылка], ссылаются также на марковские цепи, решающие деревья и CRF,
которые потом не используют (в то время как я в этой работе использую). В общем, много хороших 
разных ссылочек, которые надо изучить подробнее, чтобы что-нибудь про них написать. Или вырезать это всё в целом.

\subsubsection{Разбор алгоритма, предложенного в статье:}

Представленный алгоритм основан на идее сравнения $n$-грамм. Сравнение происходит на всём 
объёме корпуса, что увеличивает точность результата, заявляют авторы статьи. Алгоритм является итеративным, причём количество итераций определяется пользователем (что показывает, что их алгоритм является в некоторой степени полуручным.

Первым шагом алгоритма включает в себя выборку по поисковому запросу. Запрос может 
представлять собой форму слова, лемму, фразу или поиск по морфологическим параметром. 
Выборка представляет собой набор биграмм и их количество вхождений в текст. В биграмме одно 
слово является запросом, в то время как второе слово может добавляться слева или справа, данный 
параметр выбирается пользователем. Полученный список биграмм отсортировывается по частоте 
вхождений в корпус и в выборке остаются только самые частотные (например, первые 95\%, в статье 
этот параметр обычно был равен 80\%). Порог отсечения (в статье он называется <<индекс 
покрытия>>, <<covering index>>) более частотных вхождений также выбирается пользователем. 
Урезанный по порогу список биграмм используется как входные данные для второй итерации 
алгоритма: каждая биграмма ищется по корпусу как фраза и, аналогично первому шагу, 
составляются триграммы и их частоты. Точно так же выбираются самые частотные триграммы 
(третье слово может добавляться справа или слева), список обрезается по пороговому значению и,
при желании, алгоритм продолжается дальше, используя на вход уже список триграмм.

Таким образом алгоритм использует $n$-граммы для поиска $(n+1)$-грамм, некоторые из которых будут отсечены порогом, а остальные использованы в следующем шаге алгоритма.

\subsubsection{Окончание алгоритма:}

Существует такое понятие как <<точность сравнения>> (<<accuracy of matching>>) $P$, которое задаётся пользователем в процентах. Если частота $n$-граммы меньше $P$ от количества найденных $(n+1)$-грамм, то $n$-грамма считается именованной сущностью, иначе алгоритм переходит на следующую итерацию. Таким образом, в финальный результат входят самые стабильные $n$-граммы разной длины, включая результаты поиска изначального поискового запроса.

Запрос извлечения именованных сущностей представляет собой кортеж (1), где $Q_1$ и $Q_2$ никак не объясняются, $L, R$ это, соответственно, порог ограничения итераций добавления слов слева и справа, $C$ --- порог отсечения частотности на каждой итерации (covering index), $P$ --- порог для принятия решения о включении фразы в итоговый список именованных сущностей (accuracy of matching). В качестве примера они снова ссылаются на формулу (1) (скорее всего, имелась в виду формула (2) из примера).


\[Q = (Q_1, Q_2, L, R, C, P)\]

\subsubsection{Эксперименты:}

Тут, конечно, всё хитро: выставляются, естественно, только те результаты, где всё получилось хорошо, а где получилось не слишком хорошо --- об этом ничего не сказано. Исследователи перечисляют довольно много категорий, над которыми они экспериментировали, но результаты они показали на словах <<министерство>>, <<улица>>, <<язык>>, <<ресторан>> и <<корпорация>>. Одной из очевидных дополнительных тем являлись бы <<реки>>, но Невзорова at al. на реках экспериментировать не стали.

Также в данной статье очень интересный способ оценки результатов. Стандартные accuracy, precision и recall (и производная от них F-score) в статье не упоминается, к сожалению, но по тексту можно вычленить нечто на них похожее. 

TODO Допиши авторов!!!

\subsection{Low-Resource Named Entity Recognition with Cross-Lingual, Character-Level Neural Conditional Random Fields}

Что-нибудь тут напишу о том, что статья хорошая, использовала я похожую архитектуру, но не их.

\subsection{A Neural Layered Model for Nested Named Entity Recognition}

Хорошая статья, из которой я решила использовать модель. 

\subsection{Datasets and Baselines for Named Entity Recognition in Armenian Texts}

Очень вдохновляющая статья (вообще говоря, магистерская работа), которая, по факту, и стала решающей при выборе темы. Тема моей работы очень близка к теме работы данных исследователей, за исключением языка: у них, как понятно из названия, армянский язык, который так же относится к языкам малой языковой группы.

В отличие от моего случая, где существует релевантная работа, поднимавшая раньше тему моей работы, Т. Гукасян, Г. Давтян, К. Аветисян и И. Андрианов стали, можно сказать, первопроходцами в своей области, поскольку никто не делал подобных работ для армянского языка. У них не было подобранного и размеченного корпуса текста, поэтому, помимо распознавания именованных сущностей, они занимались также и сбором и разметкой данных. Их модель включала в себя CRF, которую я использую и в своей работе, и рекомендую как хорошую модель для языков с малыми ресурсами.

В своей работе исследователи не использовали BERT, поскольку это относительно новая модель, а статья вышла в конце 2018 года. У меня, к счастью, такая возможность есть, поэтому я ей воспользовалась.










