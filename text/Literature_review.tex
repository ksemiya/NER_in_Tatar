\section{Обзор литературы}

\subsection{Стандартные подходы к извлечению именованных сущностей}

На текущий момент лучшими моделями на классическом датасете CoNLL 2003 \cite{tjong-kim-sang-de-meulder-2003-introduction} \ref{table:example_CoNLL}. По оценке сайта \href{https://paperswithcode.com/sota/named-entity-recognition-ner-on-conll-2003}{paperswithcode.com} является Delta \cite{delta} (модель на основе BERT), также высокие места занимают такие модели как CNN \cite{CNN_top_2_SOTA}, GCDT \cite{Liu:19}, I-DARTS + Flair \cite{jiang-etal-2019-improved}, LSTM-CRF \cite{strakova-etal-2019-neural}.

\begin{table}[h]
\caption{Пример предложения из датасета CoNLL}
\begin{tabular}{llll}
Word & POS tag & syntactic chunk tag & named entity tag \\
U.N. & NNP & I-NP & I-ORG \\
official & NN & I-NP & O \\
Ekeus & NNP & I-NP& I-PER \\
heads & VBZ & I-VP & O\\
for & IN & I-PP & O \\
Baghdad & NNP & I-NP & I-LOC \\
. & . & O & O
\end{tabular}
\label{table:example_CoNLL}
\end{table}

\begin{figure}[h]
\includegraphics[width=\textwidth]{chart_SOTA}
\label{fig:chart_SOTA}
\caption{Лучшие модели для задачи извлечения именованных сущностей на датасете CoNLL 2003, f-мера считается по чанкам}
\end{figure}

Для более глубокого погружения в тему рекомендуется ознакомиться со всеми моделями, приведенными выше; я же проведу краткий обзор моделей, которые были использованы в работе.

\subsubsection{Low-Resource Named Entity Recognition with Cross-Lingual, Character-Level Neural Conditional Random Fields}

Ryan Cotterell и Kevin Duh  \cite{cotterell-duh-2017-low} предлагают модель условных случайных полей (Conditional Random Fields, CRF) и представляют способы её улучшения с помощью таких надстроек, как обучение модели на языках с бОльшими ресурсами, а потом применение её к языку из того же семейства, но с меньшими ресурсами. В данной работе рассматривались семья индоевропейских языков, ветви: романская, германская, славянская, индоарийская; и семья автронезийских языков, ветвь: филиппинская.

\subsubsection{A Neural Layered Model for Nested Named Entity Recognition}

Meizhi Ju, Makoto Miwa и Sophia Ananiadou  \cite{ju-etal-2018-neural} представляют модель Layered-BiLSTM-CRF, которая работает с <<наслоенными>> именованными сущностями, т.е. когда одна именованная сущность частично или полностью входит в другую именованную сущность \ref{fig:example_nested}. Используются последовательно идущие плоские слои, слой состоит из модели двунаправленной долгой краткосрочной памяти (Bidirectional long short-term memory, BiLSTM) \cite{DBLP:journals/corr/GreffSKSS15} и поверх него один слой модели условных случайных полей (Conditional Random Fields, CRF) \cite{CRF}. 

\begin{figure}[h]
\caption{Пример <<наслоенных>> именованных сущностей}
\includegraphics[width=0.9\textwidth]{example_nested}
\label{fig:example_nested}
\end{figure}


\subsubsection{BERT: Pre-training of Deep Bidirectional Transformers \\ for Language Understanding} 

Данная статья исследователей из Google AI Language\cite{DBLP:journals/corr/abs-1810-04805}, которая на момент опубликования является лучшей моделью практически на всех популярных бенчмарках обработки естественного языка. Она позволяет решать очень много задач обработки естественных языков, которые на данный момент пользуются большой популярностью. Для моей задачи очень хорошо подходит претренированная модель bert-base-multilingual-cased, в обучающие данные которой входила также и Википедия на татарском языке.

BERT --- это очень большая модель, которая не решает задачи извлечения именованных сущностей сама по себе, поэтому я воспользовалась библиотекой Transformers фирмы Huggingface \cite{Wolf2019HuggingFacesTS}

\subsubsection{Huggingface Transformers}

Данная библиотека предоставляет возможность использовать различные  модели (не только BERT, но и многие другие) для решения различных задач обработки естественного языка, в том числе и извлечения именованных сущностей.
Их \href{https://github.com/huggingface/transformers}{репозиторий на github} содержит множество \href{https://github.com/huggingface/transformers/tree/master/examples/}{примеров} для удобного использования их библиотеки.


\subsection{Стандартные подходы к разметке данных}

Текст делится на словоформы, т.е. каждый элемент в предложении отделяется от другого. Словоформами являются не только слова, но и знаки препинания, числа, эмодзи и другие всевозможные сущности.

Стандартным (самой распространённым) форматом разметки для корпусов текста для задачи извлечения именованных сущностей является разметка IOB (сокр. от Inside–outside–beginning), иногда называется BIO. Она была представлена в работе Text Chunking using Transformation-Based Learning \cite{DBLP:journals/corr/cmp-lg-9505040}. Данный формат имеет три префикса:
\begin{itemize}
\item B префикс перед тегом указывает, что тег находится в начале сегмента (в нашем случае именованной сущности)
\item I префикс перед тегом указывает, что тег находится в продолжении сегмента.
\item O метка указывает, что данное слово не относится ни к какому тегу. 
\end{itemize}
 
Теги могут быть различными; устанавливаются на усмотрение исследователя, примеры тегов: PER (персона), LOC (географический объект), ORG (организация), TIM (время) и другие. Разметка в тексте выглядит следующим образом:

\begin{tabular}[h]{ccccccc}
\textcolor{green}{B-PER} & \textcolor{green}{I-PER} & O & O & \textcolor{brown}{B-LOC} &  \textcolor{brown}{I-LOC} & O \\
Василий & Иванов & проживает & в & Российской & Федерации & . \\
\end{tabular}

Как можно видеть из примера выше, теги могут относиться не только к словоформе, но и к целым фразам, тогда они переносятся на слова с помощью меток $B-, I-$. 

Также существует проблема, когда у разных людей разное представление о том, является ли слово именованной сущностью. Например,

\begin{tabular}[h]{cccccc}
\multicolumn{2}{c}{\textcolor{red}{B-PER или O?}} & O & O & \textcolor{blue}{B-LOC} & O \\
Внук & Ахмета & живёт & в & Москве & . \\
\end{tabular}

Является ли <<внук Ахмета>> именованной сущностью? Meizhi Ju, Makoto Miwa и Sophia Ananiadou в своей работе <<A Neural Layered Model for Nested Named Entity Recognition>> \cite{ju-etal-2018-neural} приводят следующий пример \ref{table:example_nested}, где <<Mary's husband>> является именованной сущностью. Таким образом, среди людей возможны разногласия по поводу того, что отмечать как именованную сущность, а что нет.

\begin{table}[h]
\begin{tabular}[h]{cccc}
John  &  B-PER  & O  & O \\
killed & O  & O  & O \\ 
Mary  &  B-PER &  B-PER &  O \\
's  & O &  I-PER &  O \\
husband & O &  I-PER &  O \\
.  & O &  O &  O 
\end{tabular}
\caption{Пример разметки из работы \cite{ju-etal-2018-neural} }
\label{table:example_nested}
\end{table}

Когда люди размечают именованные сущности, они получают f-score равный $96.95\%$ \cite{marsh-perzanowski-1998-muc}, что означает неточность даже при разметке данных людьми. <<Золотыми>> данными являются либо данные, которые исследователи отметили как правильные, либо выбранные <<коллективно>>: один и тот же текст даётся на разметку, например, 5 людям, и если 3 из 5 высказались, что это именованная сущность, тег оказывается в <<золотых>> данных.


\subsection{Работы, связанные с извлечением именованных сущностей в малоресурсных языках}

\subsubsection{Datasets and Baselines for Named Entity Recognition in Armenian Texts}

Тема моей работы очень близка к теме работы данных исследователей, за исключением языка: у них, как понятно из названия, армянский язык, который так же относится к малоресурсным языкам.

В отличие от моего случая, где существует релевантная работа, Т. Гукасян, Г. Давтян, К. Аветисян и И. Андрианов стали, можно сказать, первопроходцами в своей области, поскольку никто не делал подобных работ для армянского языка. У них не было подобранного и размеченного корпуса текста, поэтому, помимо извлечения именованных сущностей, они занимались также и сбором и разметкой данных. Их модель включала в себя CRF, которую я использую и в своей работе, и рекомендую как хорошую модель для языков с малыми ресурсами.

В своей работе исследователи не использовали BERT, поскольку это относительно новая модель, а статья вышла в конце 2018 года.


\subsection{Работы, связанные с извлечением именованных сущностей в татарском языке}

При поиске корпусов на татарском языке я нашла корпус Туган Тел --- работу Невзоровой и др. \cite{tugan_tel}. %Также был найден корпус Deltacorpus 1.1, но из-за размера (19Мб) был отложен и корпус

\subsubsection{Developing Corpus Management System:
Architecture of System and Database}

Туган Тел -- это корпус текстов на татарском языке, разработанный Институтом прикладной
семиотики Академии наук Республики Татарстан. Корпус предназначен для широкого круга 
пользователей: лингвистов, специалистов в татарском языке, преподавателей татарского и всем 
тем, кому может понадобиться набор текстов на татарском языке. Основными функциями корпуса 
являются: поиск  по словоформе, лемме (лексеме), набору морфологических параметров. 
Существует система <<корпус-менеджер>>, которая поддерживает данные функции.  На данный 
момент существует проект разработки электронного корпуса, который также включает в себя 
автоматическую разметку корпуса. Корпус включает в  себя татарские тексты различных жанров, такие как художественная литература, тексты СМИ, тексты официальных документов, учебная литература, научные публикации и др. Каждый документ имеет метаописание, включающее в себя автора и его пол, выходные данные, дату  создания, жанр, части, главы и др. Тексты, включенные в корпус, снабжены автоматической  морфологической разметкой, которая включает в себя информацию о части речи и 
грамматической характеристики словоформы. Морфологическая разметка текстов корпуса 
выполняется автоматически с использованием модуля двухуровневого морфологического анализа 
татарского языка, реализованного в программном инструментарии PC-KIMMO. На 
декабрь 2019 года в корпусе 194 млн. словоформ. 

\subsubsection{Named Entity Recognition in Tatar: Corpus-Based Algorithm}

Самая близкая к моей работе это статья <<Named Entity Recognition in Tatar:
Corpus-Based Algorithm>> О. Невзоровой, Д. Мухамедшина и А. Галиевой, Академия наук Республики Татарстан. В статье они предлагают алгоритм разметки корпусов, используя в качестве примера корпус <<Туган Тел>> \cite{tugan_tel}, использовав следующие категории: книги, рестораны, фильмы, журналы, компании, аэропорты, корпорации, языки, колледжи, университеты, школы, магазины, музеи и больницы. 

\begin{enumerate}

\item\textbf{Использованные данные}

Исследователи использовали корпус Туган тел \cite{tugan_tel}.

\item\textbf{Разбор алгоритма, предложенного в статье:}

Представленный алгоритм основан на идее сравнения частотности $n$-грамм. Сравнение происходит на всём 
объёме корпуса, что увеличивает точность результата, заявляют авторы статьи. Алгоритм является итеративным, количество итераций (т.е. максимальная длина полученных n-грамм) определяется пользователем.

С помощью нулевого шага алгоритма получается выборка по поисковому запросу. Запрос может 
представлять собой форму слова, лемму, фразу или поиск по морфологическим параметром. 
Выборка представляет собой набор биграмм. В биграмме одно 
слово является запросом, а второе ищется по корпусу. Оба слова могут дополнительно обладать морфологическими параметрами. Далее полученный список из запроса просматривается вручную и из него удаляются биграммы, не являющиеся именованными сущностями. Полученная <<чистая>> выборка используется для первого шага алгоритма.

Полученный список биграмм ищется в корпусе и к нему добавляется третье слово, которое стоит с ним рядом в тексте; добавляться слово может слева или справа, данный параметр выбирается пользователем в начале и не меняется в ходе алгоритма. Полученный список триграмм отсортировывается по частоте 
вхождений в корпус и в выборке остаются только самые частотные. Порог отсечения (в статье он называется <<индекс 
покрытия>>, <<covering index>>) более частотных вхождений также выбирается пользователем (обычно 95\%). 
Урезанный по порогу список триграмм используется как входные данные для второй итерации 
алгоритма: каждая триграмма ищется по корпусу как фраза и, аналогично первой итерации, 
составляются 4-граммы и их частоты. Точно так же выбираются самые частотные 4-граммы, список обрезается по пороговому значению и, при желании, алгоритм продолжается дальше, используя на вход уже список 4-грамм.

Таким образом алгоритм использует $n$-граммы для поиска $(n+1)$-грамм, некоторые из которых будут отсечены порогом, а остальные использованы в следующем шаге алгоритма или попадут в список итоговых именованных сущностей.

\item\textbf{Окончание алгоритма:}

Существует такое понятие как <<точность сравнения>> (<<accuracy of matching>>) $P$, которое задаётся пользователем в процентах. Если частота $(n+1)$-граммы меньше $P$ от количества найденных $n$-грамм, то алгоритм прекращает увеличивать длину n-граммы, иначе алгоритм переходит на следующую итерацию. Таким образом, в финальный результат входят самые стабильные $n$-граммы разной длины, включая результаты поиска изначального поискового запроса.

Стоит отметить, что все сущности, выделенные на нулевом шаге алгоритма, так или иначе считаются именованными сущностями, именно поэтому необходима ручная фильтрация на нулевом этапе; вопрос только в том, сколько слов справа или слева к этой именованной сущности добавится. Если алгоритм перешёл от $n$-грамме к $n+1$-грамме, то $n$-грамма не входит в финальный результат.

Запрос извлечения именованных сущностей представляет собой кортеж \eqref{eq:1}, где $Q_1$ и $Q_2$ --- запрос в корпус-менеджер Туган Тел\cite{tugan_tel}, $L, R$ это, соответственно, порог ограничения итераций добавления слов слева и справа, $C$ --- порог отсечения частотности на каждой итерации (covering index), $P$ --- порог для принятия решения о включении фразы в итоговый список именованных сущностей (accuracy of matching).

\begin{equation}
Q = (Q_1, Q_2, L, R, C, P) \label{eq:1}
\end{equation}

\item\textbf{Эксперименты:}

Исследователи перечисляют довольно много категорий, над которыми они экспериментировали, но результаты они показали на словах <<министерство>>, <<улица>>, <<язык>>, <<ресторан>> и <<корпорация>>.

Пример запроса со словом <<министерство>> \eqref{eq:2}:

\begin{equation}
Q = ((\text{wordform}, \text{ministrlygy}, \text{<<>>}, \text{right}, 1, 10, \text{exact}), 7, 0, 95, 80)  \label{eq:2}
\end{equation}

Также в данной статье очень интересный способ оценки результатов. Стандартные precision и recall (и производная от них F-score) в статье не упоминается, но оценивание полученных результатов производится. Происходит это следующим образом: вручную просматриваются все полученные $n$-граммы и классифицируются: на именованные сущности, <<требует дополнительной очистки, тогда станет именованной сущностью>>, <<требует расширения, тогда станет именованной сущностью>>, <<это именованная сущность, но требует другой тег>>,  <<это именованная сущность, но требует дополнительной очистки и другой тег>> и некорректные, см. таблицу \ref{table:Nevzorova}. Данное оценивание не позволяет мне сравниваться с результатами Невзоровой и др. напрямую, так как в моей работе поставлена другая задача. Однако, мы можем расширить их подход к общему случаю на основе выделенных n-грамм.

\end{enumerate}


\begin{table}[h!]
 \begin{tabular}[h]{m{2.2cm}m{1.7cm}m{1.7cm}m{1.8cm}m{1.9cm}m{1.9cm}m{1.7cm}m{1.7cm}}

\hline
\hline
Class of named entity  & Correct & Require filtering & Require expansion & Correct names of subclasses & Names of subclasses that require filtering & Incorrect & Total \\
\hline
 Names of ministries & 100\% & 0\% & 0\% & 0\% & 0\% & 0\% & 50 \\
 \hline
 Street names & 72\% & 12\% & 0\% & 0\% & 0\% & 16\% & 600 \\
 \hline
 Language names & 53.5\% & 0\% & 0\% & 0\% & 0\% & 46.5\% & 471 (2310) \\
 \hline
 Restaurant names & 37.7\% & 18.3\% & 0\% & 13\% & 15.9\% & 15.1\% & 285 \\
 \hline
 Corporation names & 45.7\% & 19.6\% & 10.9\% & 21.7\% & 0\% & 2.2\% & 138 \\
\hline
\hline
\end{tabular}
\caption{Таблица 3 из статьи \cite{Nevzorova}}
\label{table:Nevzorova}
\end{table}

\subsection{Выводы}

В области извлечения именованных сущностей написано много статей и изобретено много моделей, показывающих хорошие результаты на распространённых языках. Существуют так же работы по теме извлечения именованных сущностей для малоресурсных языков. Академия наук Республики Татарстан начала работу в данном направлении для татарского языка; я же, воспользовавшись их результатами, размечу корпус текстов на татарском языке, применю существующие модели к имеющимся данным и приведу сравнение с результатами алгоритма Невзоровой и др.



%Обзор литературы. Краткое описание и характеристика релевантных работ. Для
%исследовательского проекта: позиционирование вашей работы относительно других
%современных работ (к примеру: предложенный метод эффективнее работы [1] потому-то, в
%работе исследуется дополнительный случай, который не исследуется в [2] и т.п.). Для
%программного проекта: описание похожих пограммных решений и почему их нельзя
%использовать для решения поставленной задачи. Обзор завершается разделом «Выводы», в
%котором по результатам обзора делаются выводы о дальнейшем плане работы над КР или
%ВКР.
























